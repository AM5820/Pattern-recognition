{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Braeburn\n",
      "Apple Crimson Snow\n",
      "Apple Golden 1\n",
      "Apple Golden 2\n",
      "Apple Golden 3\n",
      "Apple Granny Smith\n",
      "Apple Red 1\n",
      "Apple Red 2\n",
      "Apple Red 3\n",
      "Apple Red Delicious\n",
      "Apple Red Yellow 1\n",
      "Apple Red Yellow 2\n",
      "Apricot\n",
      "Avocado\n",
      "Avocado ripe\n",
      "Banana\n",
      "Banana Lady Finger\n",
      "Banana Red\n",
      "Cactus fruit\n",
      "Cantaloupe 1\n",
      "Cantaloupe 2\n",
      "Carambula\n",
      "Cherry 1\n",
      "Cherry 2\n",
      "Cherry Rainier\n",
      "Cherry Wax Black\n",
      "Cherry Wax Red\n",
      "Cherry Wax Yellow\n",
      "Chestnut\n",
      "Clementine\n",
      "Cocos\n",
      "Dates\n",
      "Granadilla\n",
      "Grape Blue\n",
      "Grape Pink\n",
      "Grape White\n",
      "Grape White 2\n",
      "Grape White 3\n",
      "Grape White 4\n",
      "Grapefruit Pink\n",
      "Grapefruit White\n",
      "Guava\n",
      "Hazelnut\n",
      "Huckleberry\n",
      "Kaki\n",
      "Kiwi\n",
      "Kohlrabi\n",
      "Kumquats\n",
      "Lemon\n",
      "Lemon Meyer\n",
      "Limes\n",
      "Lychee\n",
      "Mandarine\n",
      "Mango\n",
      "Mangostan\n",
      "Maracuja\n",
      "Melon Piel de Sapo\n",
      "Mulberry\n",
      "Nectarine\n",
      "Orange\n",
      "Papaya\n",
      "Passion Fruit\n",
      "Peach\n",
      "Peach 2\n",
      "Peach Flat\n",
      "Pear\n",
      "Pear Abate\n",
      "Pear Kaiser\n",
      "Pear Monster\n",
      "Pear Red\n",
      "Pear Williams\n",
      "Pepino\n",
      "Pepper Green\n",
      "Pepper Red\n",
      "Pepper Yellow\n",
      "Physalis\n",
      "Physalis with Husk\n",
      "Pineapple\n",
      "Pineapple Mini\n",
      "Pitahaya Red\n",
      "Plum\n",
      "Plum 2\n",
      "Plum 3\n",
      "Pomegranate\n",
      "Pomelo Sweetie\n",
      "Quince\n",
      "Rambutan\n",
      "Raspberry\n",
      "Redcurrant\n",
      "Salak\n",
      "Strawberry\n",
      "Strawberry Wedge\n",
      "Tamarillo\n",
      "Tangelo\n",
      "Tomato 1\n",
      "Tomato 2\n",
      "Tomato 3\n",
      "Tomato 4\n",
      "Tomato Cherry Red\n",
      "Tomato Maroon\n",
      "Walnut\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import glob\n",
    "import os\n",
    "dir = 'dataset/Training'\n",
    "ls=[]\n",
    "labels = []\n",
    "subdirs = [x[1] for x in os.walk(dir)]\n",
    "k=0\n",
    "for subdir in subdirs[0]:\n",
    "    k+=1\n",
    "    print(str(subdir))\n",
    "    c=0\n",
    "    for filename in glob.glob('dataset/Training/'+str(subdir) +'/*.jpg'):\n",
    "        if(c!=100):\n",
    "            image = Image.open(filename)\n",
    "            size = (60, 60)\n",
    "            image = ImageOps.fit(image, size, Image.ANTIALIAS)#.convert('LA')\n",
    "            pix = np.array(image)\n",
    "            pix = pix.flatten()\n",
    "            pix = pix.tolist()\n",
    "            ls.append(pix)\n",
    "            labels.append(k)\n",
    "            c+=1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10100, 10800)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.array(ls)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10100,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(dataset,labels,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7575, 10800)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at k = 1 , accuracy =  100.0%\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train,y_train)\n",
    "print(\"at k = \"+str(1)+\" , accuracy =  \"+str(knn.score(X_test,y_test)*100)+str(\"%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.96039603960396\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(C=1,gamma='scale')\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.score(X_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lan=[]\n",
    "for k in labels:\n",
    "    lab=[]\n",
    "    for x in range(1,102):   \n",
    "        if(x==k):\n",
    "            lab.append(1)\n",
    "        else:\n",
    "            lab.append(0)\n",
    "    lan.append(lab)\n",
    "lab = np.array(lan)\n",
    "train_X,test_X,train_y,test_y = train_test_split(dataset,lab,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7575, 101)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\studa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-9-1019b249abd1>:43: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-9-1019b249abd1>:47: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b\n",
    "\n",
    "x = tf.placeholder(tf.float32,shape=[None,10800])\n",
    "y_true = tf.placeholder(tf.float32,shape=[None,101])\n",
    "\n",
    "x_image = tf.reshape(x,[-1,60,60,3])\n",
    "\n",
    "convo_1 = convolutional_layer(x_image,shape=[1,1,3,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)\n",
    "\n",
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[1,1,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)\n",
    "\n",
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1,15*15*64])\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))\n",
    "\n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)\n",
    "\n",
    "y_pred = normal_full_layer(full_one_dropout,101)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "train = optimizer.minimize(cross_entropy)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epochs = 5000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        batch_x , batch_y = train_X[i:i+50],train_y[i:i+50]\n",
    "        \n",
    "        sess.run(train,feed_dict={x:batch_x,y_true:batch_y,hold_prob:0.5})\n",
    "        \n",
    "        # PRINT OUT A MESSAGE EVERY 100 epochs\n",
    "        if i%100 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is:')\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            print(sess.run(acc,feed_dict={x:test_X,y_true:test_y,hold_prob:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step 0\n",
      "Accuracy is:\n",
      "0.0071287127\n",
      "\n",
      "\n",
      "Currently on step 100\n",
      "Accuracy is:\n",
      "0.3017822\n",
      "\n",
      "\n",
      "Currently on step 200\n",
      "Accuracy is:\n",
      "0.34059405\n",
      "\n",
      "\n",
      "Currently on step 300\n",
      "Accuracy is:\n",
      "0.3449505\n",
      "\n",
      "\n",
      "Currently on step 400\n",
      "Accuracy is:\n",
      "0.34138614\n",
      "\n",
      "\n",
      "Currently on step 500\n",
      "Accuracy is:\n",
      "0.39128712\n",
      "\n",
      "\n",
      "Currently on step 600\n",
      "Accuracy is:\n",
      "0.4308911\n",
      "\n",
      "\n",
      "Currently on step 700\n",
      "Accuracy is:\n",
      "0.46059406\n",
      "\n",
      "\n",
      "Currently on step 800\n",
      "Accuracy is:\n",
      "0.46772277\n",
      "\n",
      "\n",
      "Currently on step 900\n",
      "Accuracy is:\n",
      "0.4871287\n",
      "\n",
      "\n",
      "Currently on step 1000\n",
      "Accuracy is:\n",
      "0.56\n",
      "\n",
      "\n",
      "Currently on step 1100\n",
      "Accuracy is:\n",
      "0.56514853\n",
      "\n",
      "\n",
      "Currently on step 1200\n",
      "Accuracy is:\n",
      "0.6384158\n",
      "\n",
      "\n",
      "Currently on step 1300\n",
      "Accuracy is:\n",
      "0.6451485\n",
      "\n",
      "\n",
      "Currently on step 1400\n",
      "Accuracy is:\n",
      "0.6724752\n",
      "\n",
      "\n",
      "Currently on step 1500\n",
      "Accuracy is:\n",
      "0.70138615\n",
      "\n",
      "\n",
      "Currently on step 1600\n",
      "Accuracy is:\n",
      "0.7061386\n",
      "\n",
      "\n",
      "Currently on step 1700\n",
      "Accuracy is:\n",
      "0.7425743\n",
      "\n",
      "\n",
      "Currently on step 1800\n",
      "Accuracy is:\n",
      "0.80475247\n",
      "\n",
      "\n",
      "Currently on step 1900\n",
      "Accuracy is:\n",
      "0.8\n",
      "\n",
      "\n",
      "Currently on step 2000\n",
      "Accuracy is:\n",
      "0.85821784\n",
      "\n",
      "\n",
      "Currently on step 2100\n",
      "Accuracy is:\n",
      "0.8534653\n",
      "\n",
      "\n",
      "Currently on step 2200\n",
      "Accuracy is:\n",
      "0.8388119\n",
      "\n",
      "\n",
      "Currently on step 2300\n",
      "Accuracy is:\n",
      "0.8970297\n",
      "\n",
      "\n",
      "Currently on step 2400\n",
      "Accuracy is:\n",
      "0.9045544\n",
      "\n",
      "\n",
      "Currently on step 2500\n",
      "Accuracy is:\n",
      "0.92435646\n",
      "\n",
      "\n",
      "Currently on step 2600\n",
      "Accuracy is:\n",
      "0.9140594\n",
      "\n",
      "\n",
      "Currently on step 2700\n",
      "Accuracy is:\n",
      "0.8962376\n",
      "\n",
      "\n",
      "Currently on step 2800\n",
      "Accuracy is:\n",
      "0.9136634\n",
      "\n",
      "\n",
      "Currently on step 2900\n",
      "Accuracy is:\n",
      "0.8740594\n",
      "\n",
      "\n",
      "Currently on step 3000\n",
      "Accuracy is:\n",
      "0.94336635\n",
      "\n",
      "\n",
      "Currently on step 3100\n",
      "Accuracy is:\n",
      "0.93465346\n",
      "\n",
      "\n",
      "Currently on step 3200\n",
      "Accuracy is:\n",
      "0.9310891\n",
      "\n",
      "\n",
      "Currently on step 3300\n",
      "Accuracy is:\n",
      "0.9461386\n",
      "\n",
      "\n",
      "Currently on step 3400\n",
      "Accuracy is:\n",
      "0.94336635\n",
      "\n",
      "\n",
      "Currently on step 3500\n",
      "Accuracy is:\n",
      "0.95564353\n",
      "\n",
      "\n",
      "Currently on step 3600\n",
      "Accuracy is:\n",
      "0.9631683\n",
      "\n",
      "\n",
      "Currently on step 3700\n",
      "Accuracy is:\n",
      "0.9659406\n",
      "\n",
      "\n",
      "Currently on step 3800\n",
      "Accuracy is:\n",
      "0.94257426\n",
      "\n",
      "\n",
      "Currently on step 3900\n",
      "Accuracy is:\n",
      "0.9659406\n",
      "\n",
      "\n",
      "Currently on step 4000\n",
      "Accuracy is:\n",
      "0.95247525\n",
      "\n",
      "\n",
      "Currently on step 4100\n",
      "Accuracy is:\n",
      "0.9679208\n",
      "\n",
      "\n",
      "Currently on step 4200\n",
      "Accuracy is:\n",
      "0.9481188\n",
      "\n",
      "\n",
      "Currently on step 4300\n",
      "Accuracy is:\n",
      "0.96237624\n",
      "\n",
      "\n",
      "Currently on step 4400\n",
      "Accuracy is:\n",
      "0.97821784\n",
      "\n",
      "\n",
      "Currently on step 4500\n",
      "Accuracy is:\n",
      "0.9849505\n",
      "\n",
      "\n",
      "Currently on step 4600\n",
      "Accuracy is:\n",
      "0.96871287\n",
      "\n",
      "\n",
      "Currently on step 4700\n",
      "Accuracy is:\n",
      "0.97544557\n",
      "\n",
      "\n",
      "Currently on step 4800\n",
      "Accuracy is:\n",
      "0.97742575\n",
      "\n",
      "\n",
      "Currently on step 4900\n",
      "Accuracy is:\n",
      "0.9841584\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        batch_x , batch_y = train_X[i:i+50],train_y[i:i+50]\n",
    "\n",
    "        sess.run(train,feed_dict={x:batch_x,y_true:batch_y,hold_prob:0.5})\n",
    "\n",
    "        # PRINT OUT A MESSAGE EVERY 100 epochs\n",
    "        if i%100 == 0:\n",
    "\n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is:')\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            print(sess.run(acc,feed_dict={x:test_X,y_true:test_y,hold_prob:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
