{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = digits.data , digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1347, 64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression(C=0.01,solver='liblinear',multi_class='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc = 98.29250185597624\n",
      "Test acc = 97.11111111111111\n"
     ]
    }
   ],
   "source": [
    "log.fit(X_train,y_train)\n",
    "print('Train acc = ' + str(log.score(X_train,y_train)*100))\n",
    "print('Test acc = ' + str(log.score(X_test,y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at C = 1 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.44444444444444%\n",
      "at C = 2 , Training accuracy =  99.62880475129919%  , testing accuracy = 95.77777777777777%\n",
      "at C = 3 , Training accuracy =  99.70304380103934%  , testing accuracy = 95.55555555555556%\n",
      "at C = 4 , Training accuracy =  99.77728285077951%  , testing accuracy = 95.11111111111111%\n",
      "at C = 5 , Training accuracy =  99.77728285077951%  , testing accuracy = 95.11111111111111%\n",
      "at C = 6 , Training accuracy =  99.77728285077951%  , testing accuracy = 95.33333333333334%\n",
      "at C = 7 , Training accuracy =  99.77728285077951%  , testing accuracy = 95.33333333333334%\n",
      "at C = 8 , Training accuracy =  99.77728285077951%  , testing accuracy = 95.33333333333334%\n",
      "at C = 9 , Training accuracy =  99.77728285077951%  , testing accuracy = 95.33333333333334%\n",
      "at C = 10 , Training accuracy =  99.77728285077951%  , testing accuracy = 95.33333333333334%\n",
      "at C = 11 , Training accuracy =  99.77728285077951%  , testing accuracy = 95.33333333333334%\n",
      "at C = 12 , Training accuracy =  99.77728285077951%  , testing accuracy = 95.33333333333334%\n",
      "at C = 13 , Training accuracy =  99.85152190051967%  , testing accuracy = 95.33333333333334%\n",
      "at C = 14 , Training accuracy =  99.85152190051967%  , testing accuracy = 95.33333333333334%\n",
      "at C = 15 , Training accuracy =  99.85152190051967%  , testing accuracy = 95.33333333333334%\n",
      "at C = 16 , Training accuracy =  99.85152190051967%  , testing accuracy = 95.33333333333334%\n",
      "at C = 17 , Training accuracy =  99.85152190051967%  , testing accuracy = 95.33333333333334%\n",
      "at C = 18 , Training accuracy =  99.85152190051967%  , testing accuracy = 95.11111111111111%\n",
      "at C = 19 , Training accuracy =  99.85152190051967%  , testing accuracy = 95.11111111111111%\n",
      "at C = 20 , Training accuracy =  99.85152190051967%  , testing accuracy = 95.11111111111111%\n",
      "at C = 21 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.88888888888889%\n",
      "at C = 22 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.88888888888889%\n",
      "at C = 23 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.66666666666667%\n",
      "at C = 24 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.66666666666667%\n",
      "at C = 25 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.88888888888889%\n",
      "at C = 26 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.66666666666667%\n",
      "at C = 27 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.66666666666667%\n",
      "at C = 28 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.66666666666667%\n",
      "at C = 29 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.66666666666667%\n",
      "at C = 30 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.66666666666667%\n",
      "at C = 31 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.66666666666667%\n",
      "at C = 32 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.66666666666667%\n",
      "at C = 33 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.44444444444444%\n",
      "at C = 34 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.66666666666667%\n",
      "at C = 35 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.66666666666667%\n",
      "at C = 36 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.44444444444444%\n",
      "at C = 37 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.44444444444444%\n",
      "at C = 38 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.22222222222221%\n",
      "at C = 39 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.44444444444444%\n",
      "at C = 40 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.44444444444444%\n",
      "at C = 41 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.22222222222221%\n",
      "at C = 42 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.66666666666667%\n",
      "at C = 43 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.44444444444444%\n",
      "at C = 44 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.44444444444444%\n",
      "at C = 45 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.44444444444444%\n",
      "at C = 46 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.22222222222221%\n",
      "at C = 47 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.66666666666667%\n",
      "at C = 48 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.44444444444444%\n",
      "at C = 49 , Training accuracy =  99.85152190051967%  , testing accuracy = 94.44444444444444%\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,50):\n",
    "    log = LogisticRegression(C=i,solver='liblinear',multi_class='auto')\n",
    "    log.fit(X_train,y_train)\n",
    "    train_acc = log.score(X_train,y_train)\n",
    "    test_acc = log.score(X_test,y_test)\n",
    "    print(\"at C = \"+str(i)+\" , Training accuracy =  \"+str(train_acc*100)+str(\"%\") + '  , testing accuracy = '+str(test_acc*100)+str(\"%\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "log = LogisticRegression(C=i,solver='liblinear',multi_class='auto')\n",
    "param_grid = {'C': np.arange(0.01, 25)}\n",
    "log_gscv = GridSearchCV(log, param_grid, cv=5)\n",
    "log_gscv.fit(X, y)\n",
    "log_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "seen,unseen = [],[]\n",
    "C_param = np.linspace(0.01,1,100)\n",
    "for i in C_param:\n",
    "    log = LogisticRegression(C=i,solver='liblinear',multi_class='auto')\n",
    "    log.fit(X_train,y_train)\n",
    "    train_acc = log.score(X_train,y_train)\n",
    "    test_acc = log.score(X_test,y_test)\n",
    "    seen.append(test_acc)\n",
    "    unseen.append(train_acc)\n",
    "plt.plot(C_param,seen,label='train')\n",
    "plt.plot(C_param,unseen,label='test')\n",
    "plt.ylabel(\"Accurracy\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at C = 0.01 , Training accuracy =  98.29250185597624%  , testing accuracy = 97.11111111111111%\n",
      "at C = 0.02 , Training accuracy =  98.66369710467706%  , testing accuracy = 96.66666666666667%\n",
      "at C = 0.03 , Training accuracy =  98.73793615441723%  , testing accuracy = 96.66666666666667%\n",
      "at C = 0.04 , Training accuracy =  98.88641425389754%  , testing accuracy = 96.66666666666667%\n",
      "at C = 0.05 , Training accuracy =  98.96065330363771%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.060000000000000005 , Training accuracy =  99.03489235337788%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.06999999999999999 , Training accuracy =  99.03489235337788%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.08 , Training accuracy =  99.03489235337788%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.09 , Training accuracy =  99.10913140311804%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.09999999999999999 , Training accuracy =  99.1833704528582%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.11 , Training accuracy =  99.25760950259837%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.12 , Training accuracy =  99.25760950259837%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.13 , Training accuracy =  99.25760950259837%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.14 , Training accuracy =  99.25760950259837%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.15000000000000002 , Training accuracy =  99.33184855233853%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.16 , Training accuracy =  99.4060876020787%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.17 , Training accuracy =  99.4060876020787%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.18000000000000002 , Training accuracy =  99.4060876020787%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.19 , Training accuracy =  99.4060876020787%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.2 , Training accuracy =  99.4060876020787%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.21000000000000002 , Training accuracy =  99.4060876020787%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.22 , Training accuracy =  99.4060876020787%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.23 , Training accuracy =  99.4060876020787%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.24000000000000002 , Training accuracy =  99.4060876020787%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.25 , Training accuracy =  99.4060876020787%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.26 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.27 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.28 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.29000000000000004 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.3 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.31 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.32 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.33 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.34 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.35000000000000003 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.36000000000000004 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.37 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.38 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.39 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.4 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.41000000000000003 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.42000000000000004 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.43 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.44 , Training accuracy =  99.48032665181886%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.45 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.46 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.47000000000000003 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.48000000000000004 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.49 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.5 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.51 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.52 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.53 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.54 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.55 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.56 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.5700000000000001 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.5800000000000001 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.59 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.6 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.61 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.62 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.63 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.64 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.65 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.66 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.67 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.68 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.6900000000000001 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.7000000000000001 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.7100000000000001 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.72 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.73 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.74 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.75 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.76 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.77 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.78 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.79 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.8 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.81 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.8200000000000001 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.8300000000000001 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at C = 0.8400000000000001 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.85 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.86 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.87 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.88 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.89 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.9 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.91 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.92 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.93 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.9400000000000001 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.22222222222221%\n",
      "at C = 0.9500000000000001 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.9600000000000001 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.97 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.98 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.44444444444444%\n",
      "at C = 0.99 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.44444444444444%\n",
      "at C = 1.0 , Training accuracy =  99.55456570155901%  , testing accuracy = 96.44444444444444%\n"
     ]
    }
   ],
   "source": [
    "arr = np.linspace(0.01,1,100)\n",
    "for i in arr:\n",
    "    log = LogisticRegression(C=i,solver='liblinear',multi_class='auto')\n",
    "    log.fit(X_train,y_train)\n",
    "    train_acc = log.score(X_train,y_train)\n",
    "    test_acc = log.score(X_test,y_test)\n",
    "    print(\"at C = \"+str(i)+\" , Training accuracy =  \"+str(train_acc*100)+str(\"%\") + '  , testing accuracy = '+str(test_acc*100)+str(\"%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
       "       0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21, 0.22,\n",
       "       0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32, 0.33,\n",
       "       0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43, 0.44,\n",
       "       0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54, 0.55,\n",
       "       0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65, 0.66,\n",
       "       0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77,\n",
       "       0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88,\n",
       "       0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99,\n",
       "       1.  ])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
